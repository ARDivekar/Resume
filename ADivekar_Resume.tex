% !TEX program = xelatex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is a modified ONE COLUMN version of
% the following template:
% 
% Deedy - One Page Two Column Resume
% LaTeX Template
% Version 1.1 (30/4/2014)
%
% Original author:
% Debarghya Das (http://debarghyadas.com)
%
% Original repository:
% https://github.com/deedydas/Deedy-Resume
%
% IMPORTANT: THIS TEMPLATE NEEDS TO BE COMPILED WITH XeLaTeX
%
% This template uses several fonts not included with Windows/Linux by
% default. If you get compilation errors saying a font is missing, find the line
% on which the font is used and either change it to a font included with your
% operating system or comment the line out to use the default font.
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 
% TODO:
% 1. Integrate biber/bibtex for article citation under publications.
% 2. Figure out a smoother way for the document to flow onto the next page.
% 3. Add styling information for a "Projects/Hacks" section.
% 4. Add location/address information
% 5. Merge OpenFont and MacFonts as a single sty with options.
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% CHANGELOG:
% v1.1:
% 1. Fixed several compilation bugs with \renewcommand
% 2. Got Open-source fonts (Windows/Linux support)
% 3. Added Last Updated
% 4. Move Title styling into .sty
% 5. Commented .sty file.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Known Issues:
% 1. Overflows onto second page if any column's contents are more than the
% vertical limit
% 2. Hacky space on the first bullet point on the second column.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[]{deedy-resume-openfont}

\usepackage{xcolor}
\usepackage{xstring}
\defaultfontfeatures{Path = fontawesome5/opentype/} %% Ref: https://tex.stackexchange.com/a/132893
% \usepackage{fontawesome}  %% Ref: https://tex.stackexchange.com/a/190931
\usepackage{fontawesome5}  %% Ref: https://latexdraw.com/fontawesome-ready-icons-to-use-in-latex/
\usepackage{academicons} %% Ref: https://jpswalsh.github.io/academicons/
\usepackage{setspace}
\usepackage{amsmath}

%% Ref: https://tex.stackexchange.com/a/573715
\tolerance=9999
\emergencystretch=10pt
\hyphenpenalty=10000
\exhyphenpenalty=100

\begin{document}

\newcommand{\faExperience}{\faIcon[regular]{briefcase}}
\newcommand{\faAmazonLogo}{\faIcon[regular]{amazon}}
\newcommand{\faEducation}{\faIcon[regular]{graduation-cap}}
\newcommand{\faPublications}{\faIcon[regular]{file-contract}}
\newcommand{\faSkills}{\faIcon[regular]{tools}}
\newcommand{\faProjects}{\faIcon{laptop-code}}
\newcommand{\faTalks}{\faIcon{chalkboard-teacher}}
\newcommand{\faHonors}{\faIcon{award}}
\newcommand{\faEmail}{\faIcon{envelope}}
\newcommand{\faMobilePhone}{\faIcon{mobile-alt}}
\newcommand{\faLinkedIn}{\faIcon{linkedin}}
\newcommand{\faGoogleScholar}{\aiGoogleScholar}
\newcommand{\faGitHub}{\faIcon{github}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%     LAST UPDATED DATE
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \lastupdated

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%     TITLE NAME
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\namesection{Abhishek (Adam)}{Divekar}{
    \href{mailto:adivekar@utexas.edu}{\faEmail {} adivekar@utexas.edu} 
    \quad \textbullet{} \quad 
    \href{https://scholar.google.com/citations?user=1Sf2oM4AAAAJ&hl=en&oi=sra}{\faGoogleScholar {} Google Scholar}
    \quad \textbullet{} \quad
    \href{https://github.com/ARDivekar/}{\faGitHub {} GitHub}
    \quad \textbullet{} \quad
    \href{https://www.linkedin.com/in/ardivekar}{\faLinkedIn {} LinkedIn}
    % \quad \textbullet{} \quad
    % \faMobilePhone {} $(+91) 9819712190 $
}

% \begin{center}
% \huge\color{subheadings}\custombold{Professional student}
% \end{center}

\runsection{\faEducation}{Education}

\runsubsection{The University of Texas at Austin}\descript{}\\
\descript{Master of Science in Computer Science (GPA: 4.0)}
\runsingleline{| {} Fall 2020 - Spring 2023 (expected)} \\
\subsubsectionsep
\begin{tightemize}
    \item CS383C - Advanced Linear Algebra for Computing
    \item CS394D - Deep Learning
    \item CS391L - Machine Learning
    \item CS388 - Natural Language Processing
\end{tightemize}
\sectionsep
\subsectionsep

\runsubsection{Veermata Jijabai Technological Institute}\descript{}\\
\descript{Bachelor of Technology in Information Technology (GPA: 8.74 / 10)} \runsingleline{| {} 2013 - 2017} \\
\subsubsectionsep
Undergraduate thesis: Machine Learning for Anomaly-based Network Intrusion Detection, advised by Dr. Mahesh Shirole.
\subsectionsep

\runsection{\faExperience}{Experience}

\runsubsection{Amazon}\descript{}

\descript{Applied Scientist - 2}
\runsingleline{| {} Oct 2020 \textendash{} Present, India}
\begin{tightemize}
    \item Developed AutoML framework ``DRiP'' to iteratively maximize AutoML performance while restricted by a user-defined cost budget. Paper accepted at Amazon Machine Learning Conference 2021 ($\sim$750 submissions, acceptance-rate 33\%).
    \item Proposed ``GROK'' ranking metric to judge the quality of text augmented by Machine-translation and Abstractive Summarization models (BART, T5, PEGASUS). On product-classification tasks, GROK required $\sim$70\% fewer augmented samples to achieve performance of top-beam and rule-based augmentations (Synonym Replacement, Random Deletion, etc).
\end{tightemize}
\sectionsep

\descript{Research Engineer - 1}
\runsingleline{| {} Oct 2019 \textendash{} Sep 2020, India}
\begin{tightemize}
    \item Fine-tuned and deployed AmaBERT (BERT pretrained on Amazon product text) to classify products across 10,000+ browsable categories. Fixed $\sim$8.5 MM products, improving categorization precision from 62\% to 90\%. Built automatic model re-training workflow using Apache Spark and HuggingFace. 
    \item Developed low-latency FastText Docker containers to predict UNSPSC codes. Used to correct UNSPSC for $\sim$100 MM products on amazon.com at 95\% precision \& 95\% recall.
    % \item Designed and implemented data-processing workflow-steps for AutoML platform ``Entity Prediction Service''. Contributed $\sim$160K lines of production-grade code.
\end{tightemize}
\sectionsep

\descript{Software Development Engineer - 1} \runsingleline{| {} Jul 2017 \textendash{} Sep 2019, India}
\begin{tightemize}
    \item Built purchase-authentication used by all Kindle devices in Europe. Launched secure Kindle-to-mobile \mbox{MultiFactor} authentication using SMS \& Email notifications, CSRF tokens and server-side caching.
\end{tightemize}
\sectionsep

\runsubsection{Veermata Jijabai Technological Institute}\descript{} \\
\descript{Research Assistant} \runsingleline{| {} Apr 2017 \textendash{} Jun 2017, India}
\begin{tightemize}
    \item Summer research at Dr. Mahesh Shirole's lab. Identified class-imbalance vulnerabilities in popular network intrusion dataset and proposed new dataset to handle underrepresented attacks. Paper accepted for Oral Presentation at IEEE ICCCS 2018.
\end{tightemize}

\runsection{\faPublications}{Publications}

All publication venues (including industry) follow a double-blind peer-review process.
\subsectionsep

\runsubsection{Conferences} 
\begin{tightemize}
    \item \publication{\underline{Abhishek Divekar}, Mudit Agarwal and Nikhil Rasiwasia}{2021}{Unsupervised text augmentation using Pretrained Paraphrase  Generation}{(Preprint)}{}{}
    \item \publication{\underline{Abhishek Divekar}*, Gaurav Manchanda*, Prit Raj, Abhishek Das, Karan Tanwar, Akshay Jagatap, Vinayak Puranik, Jagannathan Srinivasan, Ramakrishna Nalam and Nikhil Rasiwasia}{2021}{Squeezing the last DRiP: AutoML for cost-constrained Product classification}{Proceedings of the 9th Annual conference of Amazon Machine Learning (AMLC). Conference acceptance-rate of 33\% out of $\sim$750 submissions}{}{}
    \item \publication{\underline{Abhishek Divekar}, Meet Parekh, Vaibhav Savla, Rudra Mishra and Mahesh Shirole}{2018, Oral Presentation}{Benchmarking datasets for Anomaly-based Network Intrusion Detection: KDD CUP 99 alternatives}{Proceedings of the 3rd IEEE International Conference on Computer and Communication Systems (IEEE ICCCS)}{https://arxiv.org/pdf/1811.05372.pdf}{arXiv:1811.05372}
\end{tightemize}

\pagebreak
\runsubsection{Workshops}
\begin{tightemize}
    \item \publication{\underline{Abhishek Divekar}, Vinayak Puranik, Zhenyu Shi, Jinmiao Fu and Nikhil Rasiwasia}{2021, Oral Presentation}{LEAP: LEAf node Predictions in the wild}{2nd Amazon Selection and Catalog Services Applied Science Workshop}{}{}
    \item \publication{Andrew Borthwick, \underline{Abhishek Divekar}, Nick Erickson, Fayaz Ahmed Farooque, Oleg Kim, Nikhil Rasiwasia, Ethan Xu}{2021, Oral Presentation}{CPP MultiModal AutoML Corpus and Benchmark}{Workshop on MultiModal Learning and Fusion, Amazon Machine Learning Conference 2021}{}{}
    \item \publication{Gaurav Manchanda*, \underline{Abhishek Divekar}*, Prit Raj, Akshay Jagatap, Vinayak Puranik, Jagannathan Srinivasan, Ramakrishna Nalam and Nikhil Rasiwasia}{2020}{Entity Prediction Service: a configurable, end-to-end AutoML system for Product Classification}{Workshop on Automated Machine Learning, Amazon Machine Learning Conference 2020}{}{}
\end{tightemize}

\runsection{\faTalks}{Invited talks}
\subsectionsep
\begin{tightemize}
    \item Presented work on DRiP AutoML framework at Amazon Research Days 2021 conference.
\end{tightemize}

\runsection{\faHonors}{Awards}

\runsubsubsection{First place, Amazon Chennai ML Challenge, 2017}{}
\begin{tightemize}
    \item Kaggle-style competition with $\sim$300 participants. Task was to predict cancellation of KindleUnlimited subscriptions from user purchase \& reading history. Transformed time-series problem into classification, thereby increasing dataset from 150k to 3.5 MM samples. Trained RandomForest to predict cancellations with 89.7\% F-1.
\end{tightemize}

\runsection{\faSkills}{Skills}

\begin{minipage}[t]{.315\textwidth}
    \runsubsection{Languages} \\
    \runsubsubsection{Proficient}{100K+ lines in production}
    Python 
    \enspace \textbullet \enspace 
    Java 
    \subsectionsep
    \\
    \runsubsubsection{Familiar}{Used in work projects}
    Spark SQL
    \enspace \textbullet \enspace 
    C++
    \enspace \textbullet \enspace 
    JavaScript \\  
    HTML \& CSS \\
\end{minipage} \hfill 
\begin{minipage}[t]{.335\textwidth}
    \runsubsection{Tools}
    \\
    \runsubsubsection{Data Science}{}
    PyTorch 
    \enspace \textbullet \enspace 
    NumPy
    \enspace \textbullet \enspace 
    Pandas 
    \enspace \textbullet \enspace  
    Dask \\
    Apache Spark
    \enspace \textbullet \enspace  
    HuggingFace
    \enspace \textbullet \enspace  
    LaTeX
    \subsectionsep
    \\
    \runsubsubsection{Software Development \& MLOps}{}
    Git
    \enspace \textbullet \enspace 
    Docker 
    \enspace \textbullet \enspace 
    Streamlit
    \subsectionsep
    \\
    % \runsubsubsection{Amazon Web Services (AWS)}{}
    % SageMaker
    % \enspace \textbullet \enspace 
    % Lambda 
    % \enspace \textbullet \enspace 
    % DynamoDB \\
    % Step Functions
    % \enspace \textbullet \enspace 
    % Elastic Map Reduce \\  
\end{minipage} \hfill 
\begin{minipage}[t]{.325\textwidth}
    \runsubsection{Computer Science}
    \\
    \runsubsubsection{Machine Learning}{}
    Automated Machine Learning (AutoML) \\
    Deep Learning \\
    Natural Language Processing \\
    Computer Vision \\
    \subsectionsep
    % \\
    % \runsubsubsection{Math}{}
    % Probability and Statistics \\
    % Linear Algebra \\
    % Multivariate calculus \\
\end{minipage}
\sectionsep

\runsection{\faProjects}{Projects}

\runsubsubsection{Asking the Right Questions: Question Paraphrasing Using Cross-Domain Abstractive-Summarization and Backtranslation}{\underline{Abhishek Divekar}, Alex Stoken}

\subsubsectionsep
Final project for graduate course CS388 Natural Language Processing at UT Austin.
\begin{tightemize}
    \item Used Abstractive-Summarization model PEGASUS for data augmentation in Question-Answering. Compared results to Backtranslation augmentation (Fairseq EN$\leftrightarrow$DE WMT'19 News), on NewsQA (in-domain) \& BioASQ (cross-domain).
    \item Trained Bi-LSTM with aligned attention, using 300-dimensional GloVE embeddings. Used PyTorch.
\end{tightemize}
\sectionsep

\runsubsubsection{Autonomous agents for realtime multiplayer ice-hockey}{\underline{Abhishek Divekar}, Jason Housman, Ankita Sinha, Alex Stoken}
Final project for graduate course CS394D Deep Learning at UT Austin.
\begin{tightemize}
    \item Built autonomous agent to play ice-hockey using image signal from SuperTuxKart videogame (similar to MarioKart). 
    \item Trained multi-headed CenterNet model (with U-Net backend), to predict whether hockey puck was on-screen (classification), puck's x-y coordinates (aimpoint regression) and distance from player (regression). Model made predictions in realtime \mbox{(avg. 18ms} on NVIDIA Tesla V100 GPU for 400$\times$300 images).
    \item Model predictions used by agent-code to either search and ``dribble'' puck towards goal, or defend against opposite team.
\end{tightemize}
\sectionsep

\runsubsubsection{SearchDistribute: an economical Google Search API}{\underline{Abhishek Divekar}}

\begin{tightemize}
    \item Tool to gather datasets of search results from Google, Bing, etc. Able to retrieve $\sim$250K results/day using \$5/month VPN connection (120x savings compared to Google Search API).
    \item Built using Python and Selenium to coordinate multiple PhantomJS browser instances, each connected to a VPN proxy.
\end{tightemize}

\end{document}  \documentclass[]{article}
